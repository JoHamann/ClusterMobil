{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f1cc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import osmnx as ox\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "import contextily as ctx\n",
    "\n",
    "from shapely.geometry import MultiLineString, LineString, Point\n",
    "from shapely import wkt\n",
    "import random\n",
    "import string\n",
    "import s3fs\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "from wetterdienst.provider.dwd.observation import DwdObservationRequest, DwdObservationDataset, DwdObservationPeriod, DwdObservationResolution\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import openturns as ot\n",
    "import tqdm\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "\n",
    "from tesspy import Tessellation\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4446006c",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_data = datetime.strptime('01/Jan/2019 00:00:00', '%d/%b/%Y %H:%M:%S')\n",
    "end_data = datetime.strptime('01/Mar/2019 00:00:00', '%d/%b/%Y %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3074c9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_temp = DwdObservationRequest(parameter=[DwdObservationDataset.TEMPERATURE_AIR],\n",
    "                                resolution=DwdObservationResolution.HOURLY,\n",
    "                                start_date = start_data,\n",
    "                                end_date = end_data\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fe696a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_wind = DwdObservationRequest(parameter=[DwdObservationDataset.WIND],\n",
    "                                resolution=DwdObservationResolution.HOURLY,\n",
    "                                start_date = start_data,\n",
    "                                end_date = end_data\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4468749",
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_peripitation = DwdObservationRequest(parameter=[DwdObservationDataset.PRECIPITATION],\n",
    "                                resolution=DwdObservationResolution.HOURLY,\n",
    "                                start_date = start_data,\n",
    "                                end_date = end_data\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6d2b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_station = stations_temp.all().df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be69aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_data = stations_temp.filter_by_station_id(station_id=df_all_station.station_id.unique()).values.all().df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28a0e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_data = stations_wind.filter_by_station_id(station_id=df_all_station.station_id.unique()).values.all().df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab0be50",
   "metadata": {},
   "outputs": [],
   "source": [
    "peripitation_data = stations_peripitation.filter_by_station_id(station_id=df_all_station.station_id.unique()).values.all().df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9c923c",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_data = temp_data[temp_data.parameter=='temperature_air_mean_200']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6036c0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_data = wind_data[wind_data.parameter=='wind_speed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594bb55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "peripitation_data = peripitation_data[peripitation_data.parameter=='precipitation_height']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9596572f",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_data = temp_data.merge(df_all_station[[\"station_id\", \"latitude\",\"longitude\"]], left_on='station_id', right_on='station_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0618ede1",
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_data = wind_data.merge(df_all_station[[\"station_id\", \"latitude\",\"longitude\"]], left_on='station_id', right_on='station_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da41893",
   "metadata": {},
   "outputs": [],
   "source": [
    "peripitation_data = peripitation_data.merge(df_all_station[[\"station_id\", \"latitude\",\"longitude\"]], left_on='station_id', right_on='station_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068e5f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#temp_data.drop(columns=[\"dataset\", \"parameter\", \"quality\"], inplace=True)\n",
    "#wind_data.drop(columns=[\"dataset\", \"parameter\", \"quality\"], inplace=True)\n",
    "peripitation_data.drop(columns=[\"dataset\", \"parameter\", \"quality\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a3588c",
   "metadata": {},
   "source": [
    "## Problem: incomplete weather data\n",
    "### solution: \n",
    "\n",
    "- create DF with all stations with station_id, timestamp, lat, lon, temp_value, wind_value, peripitation_value\n",
    "- merge data based on station_id \n",
    "- fill NaN values by restriction on each hour and spatially interpolation data for whole germany for each hour\n",
    "--> 1417 spatial interpolation\n",
    "\n",
    "--> shape of overall df will be 888459 x 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1778e9d4",
   "metadata": {},
   "source": [
    "## Interpolation of all temperatur data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a97af62",
   "metadata": {},
   "outputs": [],
   "source": [
    "temperatur_dfs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa56afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps = temp_data.date.unique()\n",
    "\n",
    "\n",
    "for ts in tqdm.tqdm_notebook(timestamps): \n",
    "    tmp = temp_data[temp_data.date==ts]\n",
    "    tmp1 = tmp[tmp.value.notna()]\n",
    "    tmp2 = tmp[tmp.value.isna()]\n",
    "    \n",
    "    coords = ot.Sample(tmp1[[\"latitude\", \"longitude\"]].to_numpy())\n",
    "    values = ot.Sample(tmp1[[\"value\"]].to_numpy())\n",
    "    \n",
    "    inputDimension = 2\n",
    "    #basis = ot.ConstantBasisFactory(inputDimension).build()\n",
    "    #covarianceModel = ot.SquaredExponential([1.]*inputDimension, [1.0])\n",
    "    \n",
    "    basis = ot.Basis(0)\n",
    "    covarianceModel = ot.SphericalModel(2)\n",
    "    \n",
    "    algo = ot.KrigingAlgorithm(coords, values, covarianceModel, basis)\n",
    "    algo.run()\n",
    "    result = algo.getResult()\n",
    "    krigingMetamodel = result.getMetaModel()\n",
    "    \n",
    "    tmp2[\"value\"] = tmp2.apply(lambda x: round(krigingMetamodel([x[\"latitude\"],x[\"longitude\"]])[0],2), axis=1)\n",
    "    temperatur_dfs.append(pd.concat([tmp1,tmp2]).sort_values(by=\"station_id\"))\n",
    "    \n",
    "temperatur_data = pd.concat(temperatur_dfs)\n",
    "temperatur_data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e2ca3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "temperatur_data.sort_values([\"station_id\", \"date\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4f930b",
   "metadata": {},
   "outputs": [],
   "source": [
    "temperatur_data.to_csv(\"all_temperatur_data_20190101_20190301.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1760a9",
   "metadata": {},
   "source": [
    "## Interpolation of all wind data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac5ac87",
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_dfs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada23a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41493670",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps = wind_data.date.unique()\n",
    "\n",
    "\n",
    "for ts in tqdm.tqdm_notebook(timestamps): \n",
    "    tmp = wind_data[wind_data.date==ts]\n",
    "    tmp1 = tmp[tmp.value.notna()]\n",
    "    tmp2 = tmp[tmp.value.isna()]\n",
    "    \n",
    "    coords = ot.Sample(tmp1[[\"latitude\", \"longitude\"]].to_numpy())\n",
    "    values = ot.Sample(tmp1[[\"value\"]].to_numpy())\n",
    "\n",
    "    \n",
    "    basis = ot.Basis(0)\n",
    "    covarianceModel = ot.SphericalModel(2)\n",
    "    \n",
    "    algo = ot.KrigingAlgorithm(coords, values, covarianceModel, basis)\n",
    "    algo.run()\n",
    "    result = algo.getResult()\n",
    "    krigingMetamodel = result.getMetaModel()\n",
    "    \n",
    "    tmp2[\"value\"] = tmp2.apply(lambda x: round(krigingMetamodel([x[\"latitude\"],x[\"longitude\"]])[0],2), axis=1)\n",
    "    wind_dfs.append(pd.concat([tmp1,tmp2]).sort_values(by=\"station_id\"))\n",
    "    \n",
    "windspeed_data = pd.concat(wind_dfs)\n",
    "windspeed_data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193f8f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Interpolation error leads to some values < 0 (e.g. -0.5) these values are replaced with 0 \n",
    "windspeed_data.loc[windspeed_data['value'] < 0, 'value'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0eead12",
   "metadata": {},
   "outputs": [],
   "source": [
    "windspeed_data.sort_values([\"station_id\", \"date\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cad38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "windspeed_data.to_csv(\"all_windspeed_data_20190101_20190301.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d495c91",
   "metadata": {},
   "source": [
    "## Interpolation of all percipitation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dadc15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "perci_dfs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4f5ce2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "timestamps = peripitation_data.date.unique()\n",
    "\n",
    "\n",
    "for ts in tqdm.tqdm_notebook(timestamps):\n",
    "    tmp = peripitation_data[peripitation_data.date==ts]\n",
    "    tmp1 = tmp[tmp.value.notna()]\n",
    "    tmp2 = tmp[tmp.value.isna()]\n",
    "\n",
    "    coords = ot.Sample(tmp1[[\"latitude\", \"longitude\"]].to_numpy())\n",
    "    values = ot.Sample(tmp1[[\"value\"]].to_numpy())\n",
    "\n",
    "\n",
    "    basis = ot.Basis(0)\n",
    "    covarianceModel = ot.SphericalModel(2)\n",
    "    \n",
    "    try:\n",
    "        algo = ot.KrigingAlgorithm(coords, values, covarianceModel, basis)\n",
    "        algo.run()\n",
    "        result = algo.getResult()\n",
    "        krigingMetamodel = result.getMetaModel()\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    tmp2[\"value\"] = tmp2.apply(lambda x: round(krigingMetamodel([x[\"latitude\"],x[\"longitude\"]])[0],2), axis=1)\n",
    "    perci_dfs.append(pd.concat([tmp1,tmp2]).sort_values(by=\"station_id\"))\n",
    "        \n",
    "        \n",
    "peripitation_height_data = pd.concat(perci_dfs)\n",
    "peripitation_height_data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0108a077",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Interpolation error leads to some values < 0 (e.g. -0.5) these values are replaced with 0 \n",
    "peripitation_height_data.loc[peripitation_height_data['value'] < 0, 'value'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bc0d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "peripitation_height_data.sort_values([\"station_id\", \"date\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4991efc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "peripitation_height_data.to_csv(\"all_peripitation_height_20190101_20190301.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geospatial_parallel",
   "language": "python",
   "name": "geospatial_parallel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
